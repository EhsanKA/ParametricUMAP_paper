{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "- for each dataset, load x and z, then compute silhouette score and trustworthiness\n",
    "- save metrics to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:25.666605Z",
     "start_time": "2020-08-21T23:51:25.663650Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:26.291569Z",
     "start_time": "2020-08-21T23:51:26.288678Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import trustworthiness\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:26.451797Z",
     "start_time": "2020-08-21T23:51:26.448855Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:26.590809Z",
     "start_time": "2020-08-21T23:51:26.587889Z"
    }
   },
   "outputs": [],
   "source": [
    "from tfumap.paths import ensure_dir, MODEL_DIR, DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:26.732389Z",
     "start_time": "2020-08-21T23:51:26.729681Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = MODEL_DIR/'projections' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:26.900348Z",
     "start_time": "2020-08-21T23:51:26.879036Z"
    }
   },
   "outputs": [],
   "source": [
    "#from https://gist.github.com/AlexandreAbraham/5544803\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics.pairwise import distance_metrics\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def silhouette_score_block(X, labels, metric='euclidean', sample_size=None,\n",
    "                           random_state=None, n_jobs=1, **kwds):\n",
    "    \"\"\"Compute the mean Silhouette Coefficient of all samples.\n",
    "    The Silhouette Coefficient is calculated using the mean intra-cluster\n",
    "    distance (a) and the mean nearest-cluster distance (b) for each sample.\n",
    "    The Silhouette Coefficient for a sample is ``(b - a) / max(a, b)``.\n",
    "    To clarrify, b is the distance between a sample and the nearest cluster\n",
    "    that b is not a part of.\n",
    "    This function returns the mean Silhoeutte Coefficient over all samples.\n",
    "    To obtain the values for each sample, use silhouette_samples\n",
    "    The best value is 1 and the worst value is -1. Values near 0 indicate\n",
    "    overlapping clusters. Negative values generally indicate that a sample has\n",
    "    been assigned to the wrong cluster, as a different cluster is more similar.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array [n_samples_a, n_features]\n",
    "        Feature array.\n",
    "    labels : array, shape = [n_samples]\n",
    "             label values for each sample\n",
    "    metric : string, or callable\n",
    "        The metric to use when calculating distance between instances in a\n",
    "        feature array. If metric is a string, it must be one of the options\n",
    "        allowed by metrics.pairwise.pairwise_distances. If X is the distance\n",
    "        array itself, use \"precomputed\" as the metric.\n",
    "    sample_size : int or None\n",
    "        The size of the sample to use when computing the Silhouette\n",
    "        Coefficient. If sample_size is None, no sampling is used.\n",
    "    random_state : integer or numpy.RandomState, optional\n",
    "        The generator used to initialize the centers. If an integer is\n",
    "        given, it fixes the seed. Defaults to the global numpy random\n",
    "        number generator.\n",
    "    `**kwds` : optional keyword parameters\n",
    "        Any further parameters are passed directly to the distance function.\n",
    "        If using a scipy.spatial.distance metric, the parameters are still\n",
    "        metric dependent. See the scipy docs for usage examples.\n",
    "    Returns\n",
    "    -------\n",
    "    silhouette : float\n",
    "        Mean Silhouette Coefficient for all samples.\n",
    "    References\n",
    "    ----------\n",
    "    Peter J. Rousseeuw (1987). \"Silhouettes: a Graphical Aid to the\n",
    "        Interpretation and Validation of Cluster Analysis\". Computational\n",
    "        and Applied Mathematics 20: 53-65. doi:10.1016/0377-0427(87)90125-7.\n",
    "    http://en.wikipedia.org/wiki/Silhouette_(clustering)\n",
    "    \"\"\"\n",
    "    if sample_size is not None:\n",
    "        random_state = check_random_state(random_state)\n",
    "        indices = random_state.permutation(X.shape[0])[:sample_size]\n",
    "        if metric == \"precomputed\":\n",
    "            raise ValueError('Distance matrix cannot be precomputed')\n",
    "        else:\n",
    "            X, labels = X[indices], labels[indices]\n",
    "    sil_samp = silhouette_samples_block(\n",
    "        X, labels, metric=metric, n_jobs=n_jobs, **kwds)\n",
    "    return np.mean(sil_samp), sil_samp\n",
    "\n",
    "\n",
    "def silhouette_samples_block(X, labels, metric='euclidean', n_jobs=1, **kwds):\n",
    "    \"\"\"Compute the Silhouette Coefficient for each sample.\n",
    "    The Silhoeutte Coefficient is a measure of how well samples are clustered\n",
    "    with samples that are similar to themselves. Clustering models with a high\n",
    "    Silhouette Coefficient are said to be dense, where samples in the same\n",
    "    cluster are similar to each other, and well separated, where samples in\n",
    "    different clusters are not very similar to each other.\n",
    "    The Silhouette Coefficient is calculated using the mean intra-cluster\n",
    "    distance (a) and the mean nearest-cluster distance (b) for each sample.\n",
    "    The Silhouette Coefficient for a sample is ``(b - a) / max(a, b)``.\n",
    "    This function returns the Silhoeutte Coefficient for each sample.\n",
    "    The best value is 1 and the worst value is -1. Values near 0 indicate\n",
    "    overlapping clusters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array [n_samples_a, n_features]\n",
    "        Feature array.\n",
    "    labels : array, shape = [n_samples]\n",
    "             label values for each sample\n",
    "    metric : string, or callable\n",
    "        The metric to use when calculating distance between instances in a\n",
    "        feature array. If metric is a string, it must be one of the options\n",
    "        allowed by metrics.pairwise.pairwise_distances. If X is the distance\n",
    "        array itself, use \"precomputed\" as the metric.\n",
    "    `**kwds` : optional keyword parameters\n",
    "        Any further parameters are passed directly to the distance function.\n",
    "        If using a scipy.spatial.distance metric, the parameters are still\n",
    "        metric dependent. See the scipy docs for usage examples.\n",
    "    Returns\n",
    "    -------\n",
    "    silhouette : array, shape = [n_samples]\n",
    "        Silhouette Coefficient for each samples.\n",
    "    References\n",
    "    ----------\n",
    "    Peter J. Rousseeuw (1987). \"Silhouettes: a Graphical Aid to the\n",
    "        Interpretation and Validation of Cluster Analysis\". Computational\n",
    "        and Applied Mathematics 20: 53-65. doi:10.1016/0377-0427(87)90125-7.\n",
    "    http://en.wikipedia.org/wiki/Silhouette_(clustering)\n",
    "    \"\"\"\n",
    "    A = _intra_cluster_distances_block(X, labels, metric, n_jobs=n_jobs,\n",
    "                                       **kwds)\n",
    "    B = _nearest_cluster_distance_block(X, labels, metric, n_jobs=n_jobs,\n",
    "                                        **kwds)\n",
    "    sil_samples = (B - A) / np.maximum(A, B)\n",
    "    # nan values are for clusters of size 1, and should be 0\n",
    "    return np.nan_to_num(sil_samples)\n",
    "\n",
    "\n",
    "def _intra_cluster_distances_block_(subX, metric, **kwds):\n",
    "    distances = pairwise_distances(subX, metric=metric, **kwds)\n",
    "    return distances.sum(axis=1) / (distances.shape[0] - 1)\n",
    "\n",
    "\n",
    "def _intra_cluster_distances_block(X, labels, metric, n_jobs=1, **kwds):\n",
    "    \"\"\"Calculate the mean intra-cluster distance for sample i.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array [n_samples_a, n_features]\n",
    "        Feature array.\n",
    "    labels : array, shape = [n_samples]\n",
    "        label values for each sample\n",
    "    metric : string, or callable\n",
    "        The metric to use when calculating distance between instances in a\n",
    "        feature array. If metric is a string, it must be one of the options\n",
    "        allowed by metrics.pairwise.pairwise_distances. If X is the distance\n",
    "        array itself, use \"precomputed\" as the metric.\n",
    "    `**kwds` : optional keyword parameters\n",
    "        Any further parameters are passed directly to the distance function.\n",
    "        If using a scipy.spatial.distance metric, the parameters are still\n",
    "        metric dependent. See the scipy docs for usage examples.\n",
    "    Returns\n",
    "    -------\n",
    "    a : array [n_samples_a]\n",
    "        Mean intra-cluster distance\n",
    "    \"\"\"\n",
    "    intra_dist = np.zeros(labels.size, dtype=float)\n",
    "    values = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(_intra_cluster_distances_block_)\n",
    "                (X[np.where(labels == label)[0]], metric, **kwds)\n",
    "                for label in np.unique(labels))\n",
    "    for label, values_ in zip(np.unique(labels), values):\n",
    "        intra_dist[np.where(labels == label)[0]] = values_\n",
    "    return intra_dist\n",
    "\n",
    "\n",
    "def _nearest_cluster_distance_block_(subX_a, subX_b, metric, **kwds):\n",
    "    dist = pairwise_distances(subX_a, subX_b, metric=metric, **kwds)\n",
    "    dist_a = dist.mean(axis=1)\n",
    "    dist_b = dist.mean(axis=0)\n",
    "    return dist_a, dist_b\n",
    "\n",
    "\n",
    "def _nearest_cluster_distance_block(X, labels, metric, n_jobs=1, **kwds):\n",
    "    \"\"\"Calculate the mean nearest-cluster distance for sample i.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array [n_samples_a, n_features]\n",
    "        Feature array.\n",
    "    labels : array, shape = [n_samples]\n",
    "        label values for each sample\n",
    "    metric : string, or callable\n",
    "        The metric to use when calculating distance between instances in a\n",
    "        feature array. If metric is a string, it must be one of the options\n",
    "        allowed by metrics.pairwise.pairwise_distances. If X is the distance\n",
    "        array itself, use \"precomputed\" as the metric.\n",
    "    `**kwds` : optional keyword parameters\n",
    "        Any further parameters are passed directly to the distance function.\n",
    "        If using a scipy.spatial.distance metric, the parameters are still\n",
    "        metric dependent. See the scipy docs for usage examples.\n",
    "    X : array [n_samples_a, n_features]\n",
    "        Feature array.\n",
    "    Returns\n",
    "    -------\n",
    "    b : float\n",
    "        Mean nearest-cluster distance for sample i\n",
    "    \"\"\"\n",
    "    inter_dist = np.empty(labels.size, dtype=float)\n",
    "    inter_dist.fill(np.inf)\n",
    "    # Compute cluster distance between pairs of clusters\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    values = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(_nearest_cluster_distance_block_)(\n",
    "                X[np.where(labels == label_a)[0]],\n",
    "                X[np.where(labels == label_b)[0]],\n",
    "                metric, **kwds)\n",
    "                for label_a, label_b in combinations(unique_labels, 2))\n",
    "\n",
    "    for (label_a, label_b), (values_a, values_b) in \\\n",
    "            zip(combinations(unique_labels, 2), values):\n",
    "\n",
    "            indices_a = np.where(labels == label_a)[0]\n",
    "            inter_dist[indices_a] = np.minimum(values_a, inter_dist[indices_a])\n",
    "            del indices_a\n",
    "            indices_b = np.where(labels == label_b)[0]\n",
    "            inter_dist[indices_b] = np.minimum(values_b, inter_dist[indices_b])\n",
    "            del indices_b\n",
    "    return inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:27.024270Z",
     "start_time": "2020-08-21T23:51:27.016497Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns = ['dataset', 'class_', 'dim', 'trustworthiness', 'silhouette_score', 'silhouette_samples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:33.538307Z",
     "start_time": "2020-08-21T23:51:27.621313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# load dataset\n",
    "(train_images, Y_train), (test_images, Y_test) = cifar10.load_data()\n",
    "X_train = (train_images/255.).astype('float32')\n",
    "X_test = (test_images/255.).astype('float32')\n",
    "X_train = X_train.reshape((len(X_train), np.product(np.shape(X_train)[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n",
    "\n",
    "# subset a validation set\n",
    "n_valid = 10000\n",
    "X_valid = X_train[-n_valid:]\n",
    "Y_valid = Y_train[-n_valid:].flatten()\n",
    "X_train = X_train[:-n_valid]\n",
    "Y_train = Y_train[:-n_valid].flatten()\n",
    "Y_test = Y_test.flatten()\n",
    "\n",
    "print(len(X_train), len(X_valid), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:52:53.753835Z",
     "start_time": "2020-08-21T23:52:53.750377Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape((len(X_train), 32*32*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:33.542532Z",
     "start_time": "2020-08-21T23:51:33.539996Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:33.668050Z",
     "start_time": "2020-08-21T23:51:33.665760Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = ['umap-learn', 'direct', 'network', 'autoencoder', 'PCA', 'TSNE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:37.535329Z",
     "start_time": "2020-08-21T23:51:37.078184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/umap-learn\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/direct\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/network\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/autoencoder\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/PCA\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/TSNE\n"
     ]
    }
   ],
   "source": [
    "projection_df = pd.DataFrame(columns = ['dataset', 'class_', 'train_z', 'train_label'])\n",
    "for class_ in classes:\n",
    "    print(output_dir / dataset / class_)\n",
    "    z = np.load(output_dir / dataset / class_ / 'z.npy')\n",
    "    projection_df.loc[len(projection_df)] = [dataset, class_, z, Y_train]\n",
    "projection_df['dim'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:40.830613Z",
     "start_time": "2020-08-21T23:51:40.041050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/64/umap-learn/z.npy\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/64/direct/z.npy\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/64/network/z.npy\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/64/autoencoder/z.npy\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/64/PCA/z.npy\n",
      "/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/64/TSNE/z.npy\n",
      "[Errno 2] No such file or directory: '/mnt/cube/tsainbur/Projects/github_repos/umap_tf_networks/models/projections/cifar10/64/TSNE/z.npy'\n"
     ]
    }
   ],
   "source": [
    "projection_df_64 = pd.DataFrame(columns = ['dataset', 'class_', 'train_z', 'train_label'])\n",
    "for class_ in classes:\n",
    "    print(output_dir / dataset / '64' / class_ / 'z.npy')\n",
    "    try:\n",
    "        z = np.load(output_dir / dataset / '64' / class_ / 'z.npy')\n",
    "        projection_df_64.loc[len(projection_df_64)] = [dataset, class_, z, Y_train]\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "projection_df_64['dim'] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:51:42.826875Z",
     "start_time": "2020-08-21T23:51:42.491699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>class_</th>\n",
       "      <th>train_z</th>\n",
       "      <th>train_label</th>\n",
       "      <th>dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>umap-learn</td>\n",
       "      <td>[[7.1060157, 9.195796, 7.6382084, 7.2188716, 5...</td>\n",
       "      <td>[6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>direct</td>\n",
       "      <td>[[1.0066352, -0.98004335, -0.34852365, 0.21314...</td>\n",
       "      <td>[6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>network</td>\n",
       "      <td>[[-0.05073797, 0.15603174, -0.20267391, 0.0221...</td>\n",
       "      <td>[6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>autoencoder</td>\n",
       "      <td>[[0.09604484, -0.09921512, -0.10305964, -0.012...</td>\n",
       "      <td>[6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>PCA</td>\n",
       "      <td>[[-6.3943524, 2.7541623, 1.4807999, -1.903707,...</td>\n",
       "      <td>[6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       class_                                            train_z  \\\n",
       "0  cifar10   umap-learn  [[7.1060157, 9.195796, 7.6382084, 7.2188716, 5...   \n",
       "1  cifar10       direct  [[1.0066352, -0.98004335, -0.34852365, 0.21314...   \n",
       "2  cifar10      network  [[-0.05073797, 0.15603174, -0.20267391, 0.0221...   \n",
       "3  cifar10  autoencoder  [[0.09604484, -0.09921512, -0.10305964, -0.012...   \n",
       "4  cifar10          PCA  [[-6.3943524, 2.7541623, 1.4807999, -1.903707,...   \n",
       "\n",
       "                                         train_label  dim  \n",
       "0  [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...   64  \n",
       "1  [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...   64  \n",
       "2  [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...   64  \n",
       "3  [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...   64  \n",
       "4  [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, ...   64  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_df_64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### compute silhouette score and trustworthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:55:13.110635Z",
     "start_time": "2020-08-21T23:53:20.092726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d353dce5c76742f59729e645b0e3fa04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8309924699759808\n",
      "0.8451649739791833\n",
      "0.8186705584467574\n",
      "0.8273451261008807\n",
      "0.8201575820656526\n",
      "0.9215858426741393\n",
      "0.9209458206565252\n",
      "0.9104933847077662\n",
      "0.9139511709367494\n",
      "0.9199400760608487\n",
      "0.9995521697357886\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(pd.concat([projection_df, projection_df_64]).iterrows(), total = len(projection_df)+ len(projection_df_64)):\n",
    "    #ss, sil_samp = silhouette_score_block(row.train_z, row.train_label, n_jobs = -1)\n",
    "    tw = trustworthiness(X_train_flat[:10000], row.train_z[:10000])\n",
    "    print(tw)\n",
    "    metrics_df.loc[len(metrics_df)] = [dataset, row.class_, row.dim, tw, np.nan, np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T23:55:13.122859Z",
     "start_time": "2020-08-21T23:55:13.112262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>class_</th>\n",
       "      <th>dim</th>\n",
       "      <th>trustworthiness</th>\n",
       "      <th>silhouette_score</th>\n",
       "      <th>silhouette_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>umap-learn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>umap-learn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0.845165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>network</td>\n",
       "      <td>2</td>\n",
       "      <td>0.818671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>autoencoder</td>\n",
       "      <td>2</td>\n",
       "      <td>0.827345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>PCA</td>\n",
       "      <td>2</td>\n",
       "      <td>0.820158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>TSNE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.921586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>umap-learn</td>\n",
       "      <td>64</td>\n",
       "      <td>0.920946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>direct</td>\n",
       "      <td>64</td>\n",
       "      <td>0.910493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>network</td>\n",
       "      <td>64</td>\n",
       "      <td>0.913951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>autoencoder</td>\n",
       "      <td>64</td>\n",
       "      <td>0.919940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>PCA</td>\n",
       "      <td>64</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset       class_ dim  trustworthiness  silhouette_score  \\\n",
       "0   cifar10   umap-learn   2         0.830992               NaN   \n",
       "1   cifar10   umap-learn   2         0.830992               NaN   \n",
       "2   cifar10       direct   2         0.845165               NaN   \n",
       "3   cifar10      network   2         0.818671               NaN   \n",
       "4   cifar10  autoencoder   2         0.827345               NaN   \n",
       "5   cifar10          PCA   2         0.820158               NaN   \n",
       "6   cifar10         TSNE   2         0.921586               NaN   \n",
       "7   cifar10   umap-learn  64         0.920946               NaN   \n",
       "8   cifar10       direct  64         0.910493               NaN   \n",
       "9   cifar10      network  64         0.913951               NaN   \n",
       "10  cifar10  autoencoder  64         0.919940               NaN   \n",
       "11  cifar10          PCA  64         0.999552               NaN   \n",
       "\n",
       "    silhouette_samples  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "5                  NaN  \n",
       "6                  NaN  \n",
       "7                  NaN  \n",
       "8                  NaN  \n",
       "9                  NaN  \n",
       "10                 NaN  \n",
       "11                 NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
