{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we need to train a parametric-umap network for each dataset... (5 datasets x 2 dimensions)\n",
    "For umap-learn, UMAP AE, Param. UMAP, PCA\n",
    "- load dataset\n",
    "- load network\n",
    "- compute reconstruction MSE\n",
    "- count time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:13.808808Z",
     "start_time": "2020-07-17T23:37:13.796106Z"
    }
   },
   "outputs": [],
   "source": [
    "# reload packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose GPU (this may not be needed on your computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:13.818987Z",
     "start_time": "2020-07-17T23:37:13.809962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:17.891302Z",
     "start_time": "2020-07-17T23:37:13.820105Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpu_devices)>0:\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:22.498066Z",
     "start_time": "2020-07-17T23:37:17.894645Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:22.594378Z",
     "start_time": "2020-07-17T23:37:22.499828Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from tfumap.umap import tfUMAP\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:22.634909Z",
     "start_time": "2020-07-17T23:37:22.596689Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:22.799567Z",
     "start_time": "2020-07-17T23:37:22.636193Z"
    }
   },
   "outputs": [],
   "source": [
    "from tfumap.paths import ensure_dir, MODEL_DIR, DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:22.842204Z",
     "start_time": "2020-07-17T23:37:22.801038Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = MODEL_DIR/'projections' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:22.885718Z",
     "start_time": "2020-07-17T23:37:22.843638Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction_acc_df = pd.DataFrame(columns = ['method_', 'dimensions', 'dataset', 'MSE', 'MAE', 'MedAE', 'R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:22.926412Z",
     "start_time": "2020-07-17T23:37:22.886918Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction_speed_df = pd.DataFrame(columns = ['method_', 'dimensions', 'dataset', 'embed_time', 'recon_time', 'speed', 'nex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:22.964053Z",
     "start_time": "2020-07-17T23:37:22.927833Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'cassins_dtw'\n",
    "dims = (32,31,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:27.135479Z",
     "start_time": "2020-07-17T23:37:22.965281Z"
    }
   },
   "outputs": [],
   "source": [
    "from tfumap.paths import ensure_dir, MODEL_DIR, DATA_DIR\n",
    "\n",
    "syllable_df = pd.read_pickle(DATA_DIR/'cassins'/ 'cassins.pickle')\n",
    "\n",
    "top_labels = (\n",
    "    pd.DataFrame(\n",
    "        {i: [np.sum(syllable_df.labels.values == i)] for i in syllable_df.labels.unique()}\n",
    "    )\n",
    "    .T.sort_values(by=0, ascending=False)[:20]\n",
    "    .T\n",
    ")\n",
    "\n",
    "sylllable_df = syllable_df[syllable_df.labels.isin(top_labels.columns)]\n",
    "\n",
    "\n",
    "sylllable_df = sylllable_df.reset_index()\n",
    "\n",
    "specs = np.array(list(sylllable_df.spectrogram.values))\n",
    "specs.shape\n",
    "\n",
    "sylllable_df['subset'] = 'train'\n",
    "sylllable_df.loc[:1000, 'subset'] = 'valid'\n",
    "sylllable_df.loc[1000:1999, 'subset'] = 'test'\n",
    "\n",
    "\n",
    "Y_train = np.array(list(sylllable_df.labels.values[sylllable_df.subset == 'train']))\n",
    "Y_valid = np.array(list(sylllable_df.labels.values[sylllable_df.subset == 'valid']))\n",
    "Y_test = np.array(list(sylllable_df.labels.values[sylllable_df.subset == 'test']))\n",
    "\n",
    "X_train = np.array(list(sylllable_df.spectrogram.values[sylllable_df.subset == 'train'])) #/ 255.\n",
    "X_valid = np.array(list(sylllable_df.spectrogram.values[sylllable_df.subset == 'valid']))# / 255.\n",
    "X_test = np.array(list(sylllable_df.spectrogram.values[sylllable_df.subset == 'test'])) #/ 255.\n",
    "\n",
    "X_train_flat = X_train.reshape((len(X_train), np.product(np.shape(X_train)[1:])))\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "Y_train = enc.fit_transform([[i] for i in Y_train]).astype('int').flatten()\n",
    "\n",
    "X_test_flat = X_test.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:41:26.655834Z",
     "start_time": "2020-07-17T23:41:26.611992Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape((len(X_test), 32,31,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:41:27.420023Z",
     "start_time": "2020-07-17T23:41:27.378337Z"
    }
   },
   "outputs": [],
   "source": [
    "load_loc = output_dir / dataset / 'autoencoder' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:41:27.545754Z",
     "start_time": "2020-07-17T23:41:27.499680Z"
    }
   },
   "outputs": [],
   "source": [
    "embedder = tfUMAP(\n",
    "    direct_embedding=False,\n",
    "    verbose=True,\n",
    "    negative_sample_rate=5,\n",
    "    training_epochs=5,\n",
    "    decoding_method = \"autoencoder\",\n",
    "    batch_size = 100,\n",
    "    dims = dims\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:41:29.122614Z",
     "start_time": "2020-07-17T23:41:27.647882Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = tf.keras.models.load_model((load_loc / 'encoder').as_posix())\n",
    "embedder.encoder = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:41:30.635680Z",
     "start_time": "2020-07-17T23:41:29.123885Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = tf.keras.models.load_model((load_loc / 'decoder').as_posix())\n",
    "embedder.decoder = decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:41:33.000574Z",
     "start_time": "2020-07-17T23:41:30.636929Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1024000 into shape (1000,992)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e8ebc4af4bc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_recon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1024000 into shape (1000,992)"
     ]
    }
   ],
   "source": [
    "X_recon = decoder(encoder(X_test)).numpy()\n",
    "x_real = X_test.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n",
    "x_recon = X_recon.reshape((len(X_test), np.product(np.shape(X_test)[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.258346Z",
     "start_time": "2020-07-17T23:37:13.802Z"
    }
   },
   "outputs": [],
   "source": [
    "MSE = mean_squared_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MAE = mean_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MedAE = median_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "R2 = r2_score(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.259066Z",
     "start_time": "2020-07-17T23:37:13.804Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction_acc_df.loc[len(reconstruction_acc_df)] = ['AE', 2, dataset, MSE, MAE, MedAE, R2]\n",
    "reconstruction_acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 64 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.259525Z",
     "start_time": "2020-07-17T23:37:13.806Z"
    }
   },
   "outputs": [],
   "source": [
    "load_loc = output_dir / dataset / '64' / 'autoencoder' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.260051Z",
     "start_time": "2020-07-17T23:37:13.807Z"
    }
   },
   "outputs": [],
   "source": [
    "embedder = tfUMAP(\n",
    "    direct_embedding=False,\n",
    "    verbose=True,\n",
    "    negative_sample_rate=5,\n",
    "    training_epochs=5,\n",
    "    decoding_method = \"autoencoder\",\n",
    "    batch_size = 100,\n",
    "    dims = dims\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.260589Z",
     "start_time": "2020-07-17T23:37:13.809Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = tf.keras.models.load_model((load_loc / 'encoder').as_posix())\n",
    "embedder.encoder = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.261063Z",
     "start_time": "2020-07-17T23:37:13.810Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = tf.keras.models.load_model((load_loc / 'decoder').as_posix())\n",
    "embedder.decoder = decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.261732Z",
     "start_time": "2020-07-17T23:37:13.811Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "X_recon = decoder(encoder(X_test)).numpy()\n",
    "x_real = X_test.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n",
    "x_recon = X_recon.reshape((len(X_test), np.product(np.shape(X_test)[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.262281Z",
     "start_time": "2020-07-17T23:37:13.813Z"
    }
   },
   "outputs": [],
   "source": [
    "MSE = mean_squared_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MAE = mean_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MedAE = median_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "R2 = r2_score(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.262747Z",
     "start_time": "2020-07-17T23:37:13.815Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction_acc_df.loc[len(reconstruction_acc_df)] = ['AE', 64, dataset, MSE, MAE, MedAE, R2]\n",
    "reconstruction_acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.263271Z",
     "start_time": "2020-07-17T23:37:13.817Z"
    }
   },
   "outputs": [],
   "source": [
    "load_loc = output_dir / dataset / 'recon-network' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.263760Z",
     "start_time": "2020-07-17T23:37:13.819Z"
    }
   },
   "outputs": [],
   "source": [
    "embedder = tfUMAP(\n",
    "    direct_embedding=False,\n",
    "    verbose=True,\n",
    "    negative_sample_rate=5,\n",
    "    training_epochs=5,\n",
    "    decoding_method = \"network\",\n",
    "    batch_size = 100,\n",
    "    dims = dims\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.264556Z",
     "start_time": "2020-07-17T23:37:13.820Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = tf.keras.models.load_model((load_loc / 'encoder').as_posix())\n",
    "embedder.encoder = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.265251Z",
     "start_time": "2020-07-17T23:37:13.821Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = tf.keras.models.load_model((load_loc / 'decoder').as_posix())\n",
    "embedder.decoder = decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.265926Z",
     "start_time": "2020-07-17T23:37:13.823Z"
    }
   },
   "outputs": [],
   "source": [
    "n_repeats = 10\n",
    "for i in tqdm(range(n_repeats)):\n",
    "    start_time = time.monotonic()\n",
    "    z_test = encoder(X_test)\n",
    "    end_time = time.monotonic()\n",
    "    print(\"seconds: \", end_time - start_time)\n",
    "    embed_time = end_time - start_time\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    x_test_recon = decoder(z_test)\n",
    "    end_time = time.monotonic()\n",
    "    print(\"seconds: \", end_time - start_time)\n",
    "    recon_time = end_time - start_time\n",
    "    reconstruction_speed_df.loc[len(reconstruction_speed_df)] = [\n",
    "        \"network\",\n",
    "        2,\n",
    "        dataset,\n",
    "        embed_time,\n",
    "        recon_time,\n",
    "        embed_time + recon_time,\n",
    "        len(X_test_flat)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.266656Z",
     "start_time": "2020-07-17T23:37:13.825Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    n_repeats = 10\n",
    "    for i in tqdm(range(n_repeats)):\n",
    "        start_time = time.monotonic()\n",
    "        z_test = encoder(X_test)\n",
    "        end_time = time.monotonic()\n",
    "        print(\"seconds: \", end_time - start_time)\n",
    "        embed_time = end_time - start_time\n",
    "\n",
    "        start_time = time.monotonic()\n",
    "        x_test_recon = decoder(z_test)\n",
    "        end_time = time.monotonic()\n",
    "        print(\"seconds: \", end_time - start_time)\n",
    "        recon_time = end_time - start_time\n",
    "        reconstruction_speed_df.loc[len(reconstruction_speed_df)] = [\n",
    "            \"network-cpu\",\n",
    "            2,\n",
    "            dataset,\n",
    "            embed_time,\n",
    "            recon_time,\n",
    "            embed_time + recon_time,\n",
    "        len(X_test_flat)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.267417Z",
     "start_time": "2020-07-17T23:37:13.826Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "X_recon = decoder(encoder(X_test)).numpy()\n",
    "x_real = X_test.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n",
    "x_recon = X_recon.reshape((len(X_test), np.product(np.shape(X_test)[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.268248Z",
     "start_time": "2020-07-17T23:37:13.828Z"
    }
   },
   "outputs": [],
   "source": [
    "MSE = mean_squared_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MAE = mean_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MedAE = median_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "R2 = r2_score(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.268988Z",
     "start_time": "2020-07-17T23:37:13.829Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction_acc_df.loc[len(reconstruction_acc_df)] = ['network', 2, dataset, MSE, MAE, MedAE, R2]\n",
    "reconstruction_acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 64 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.269677Z",
     "start_time": "2020-07-17T23:37:13.831Z"
    }
   },
   "outputs": [],
   "source": [
    "load_loc = output_dir / dataset / '64' / 'recon-network' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.270400Z",
     "start_time": "2020-07-17T23:37:13.834Z"
    }
   },
   "outputs": [],
   "source": [
    "embedder = tfUMAP(\n",
    "    direct_embedding=False,\n",
    "    verbose=True,\n",
    "    negative_sample_rate=5,\n",
    "    training_epochs=5,\n",
    "    decoding_method = \"autoencoder\",\n",
    "    batch_size = 100,\n",
    "    dims = dims\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.271077Z",
     "start_time": "2020-07-17T23:37:13.836Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = tf.keras.models.load_model((load_loc / 'encoder').as_posix())\n",
    "embedder.encoder = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.272180Z",
     "start_time": "2020-07-17T23:37:13.837Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = tf.keras.models.load_model((load_loc / 'decoder').as_posix())\n",
    "embedder.decoder = decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.273196Z",
     "start_time": "2020-07-17T23:37:13.839Z"
    }
   },
   "outputs": [],
   "source": [
    "n_repeats = 10\n",
    "for i in tqdm(range(n_repeats)):\n",
    "    start_time = time.monotonic()\n",
    "    z_test = encoder(X_test)\n",
    "    end_time = time.monotonic()\n",
    "    print(\"seconds: \", end_time - start_time)\n",
    "    embed_time = end_time - start_time\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    x_test_recon = decoder(z_test)\n",
    "    end_time = time.monotonic()\n",
    "    print(\"seconds: \", end_time - start_time)\n",
    "    recon_time = end_time - start_time\n",
    "    reconstruction_speed_df.loc[len(reconstruction_speed_df)] = [\n",
    "        \"network\",\n",
    "        64,\n",
    "        dataset,\n",
    "        embed_time,\n",
    "        recon_time,\n",
    "        embed_time + recon_time,\n",
    "        len(X_test_flat)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.274036Z",
     "start_time": "2020-07-17T23:37:13.841Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    n_repeats = 10\n",
    "    for i in tqdm(range(n_repeats)):\n",
    "        start_time = time.monotonic()\n",
    "        z_test = encoder(X_test)\n",
    "        end_time = time.monotonic()\n",
    "        print(\"seconds: \", end_time - start_time)\n",
    "        embed_time = end_time - start_time\n",
    "\n",
    "        start_time = time.monotonic()\n",
    "        x_test_recon = decoder(z_test)\n",
    "        end_time = time.monotonic()\n",
    "        print(\"seconds: \", end_time - start_time)\n",
    "        recon_time = end_time - start_time\n",
    "        reconstruction_speed_df.loc[len(reconstruction_speed_df)] = [\n",
    "            \"network-cpu\",\n",
    "            64,\n",
    "            dataset,\n",
    "            embed_time,\n",
    "            recon_time,\n",
    "            embed_time + recon_time,\n",
    "        len(X_test_flat)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.274891Z",
     "start_time": "2020-07-17T23:37:13.844Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction_speed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.275683Z",
     "start_time": "2020-07-17T23:37:13.846Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "X_recon = decoder(encoder(X_test)).numpy()\n",
    "x_real = X_test.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n",
    "x_recon = X_recon.reshape((len(X_test), np.product(np.shape(X_test)[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.277268Z",
     "start_time": "2020-07-17T23:37:13.847Z"
    }
   },
   "outputs": [],
   "source": [
    "MSE = mean_squared_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MAE = mean_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MedAE = median_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "R2 = r2_score(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.278344Z",
     "start_time": "2020-07-17T23:37:13.849Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction_acc_df.loc[len(reconstruction_acc_df)] = ['network', 64, dataset, MSE, MAE, MedAE, R2]\n",
    "reconstruction_acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UMAP-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.279459Z",
     "start_time": "2020-07-17T23:37:13.851Z"
    }
   },
   "outputs": [],
   "source": [
    "embedder = UMAP(n_components = 2, verbose=True)\n",
    "z_umap = embedder.fit_transform(X_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.280739Z",
     "start_time": "2020-07-17T23:37:13.853Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_samples= []\n",
    "x_test_recon_samples= []\n",
    "n_repeats = 10\n",
    "for i in tqdm(range(n_repeats)):\n",
    "    start_time = time.monotonic()\n",
    "    z_test = embedder.transform(X_test_flat);\n",
    "    end_time = time.monotonic()\n",
    "    print('seconds: ', end_time - start_time)\n",
    "    embed_time = end_time - start_time\n",
    "\n",
    "    nex = 10 # it would take far too long to reconstruct the entire dataset\n",
    "    samp_idx = np.random.randint(len(z_test),  size= nex)\n",
    "    sample = np.array(z_test)[samp_idx]\n",
    "    x_test_samples.append(samp_idx)\n",
    "    start_time = time.monotonic()\n",
    "    x_test_recon = embedder.inverse_transform(sample);\n",
    "    end_time = time.monotonic()\n",
    "    print('seconds: ', end_time - start_time)\n",
    "    recon_time = (end_time - start_time)*len(z_test)/nex\n",
    "\n",
    "    reconstruction_speed_df.loc[len(reconstruction_speed_df)] = [\n",
    "        \"umap-learn\",\n",
    "        2,\n",
    "        dataset,\n",
    "        embed_time,\n",
    "        recon_time,\n",
    "        embed_time + recon_time,\n",
    "        len(X_test_flat)\n",
    "    ]\n",
    "    x_test_recon_samples.append(x_test_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.281754Z",
     "start_time": "2020-07-17T23:37:13.855Z"
    }
   },
   "outputs": [],
   "source": [
    "x_recon = np.concatenate(x_test_recon_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.282744Z",
     "start_time": "2020-07-17T23:37:13.856Z"
    }
   },
   "outputs": [],
   "source": [
    "x_real = np.array(X_test_flat)[np.concatenate(x_test_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.283727Z",
     "start_time": "2020-07-17T23:37:13.858Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "MSE = mean_squared_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MAE = mean_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MedAE = median_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "R2 = r2_score(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "\n",
    "reconstruction_acc_df.loc[len(reconstruction_acc_df)] = ['umap-learn', 2, dataset, MSE, MAE, MedAE, R2]\n",
    "reconstruction_acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T18:45:10.741411Z",
     "start_time": "2020-07-17T18:44:51.265Z"
    }
   },
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.284901Z",
     "start_time": "2020-07-17T23:37:13.860Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "z = pca.fit_transform(X_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.286320Z",
     "start_time": "2020-07-17T23:37:13.861Z"
    }
   },
   "outputs": [],
   "source": [
    "n_repeats = 10\n",
    "for i in tqdm(range(n_repeats)):\n",
    "    start_time = time.monotonic()\n",
    "    z_test = pca.transform(X_test_flat);\n",
    "    end_time = time.monotonic()\n",
    "    print('seconds: ', end_time - start_time)\n",
    "    embed_time = end_time - start_time\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    x_test_recon = pca.inverse_transform(z_test);\n",
    "    end_time = time.monotonic()\n",
    "    print('seconds: ', end_time - start_time)\n",
    "    recon_time = (end_time - start_time)\n",
    "\n",
    "    reconstruction_speed_df.loc[len(reconstruction_speed_df)] = [\n",
    "        \"pca\",\n",
    "        2,\n",
    "        dataset,\n",
    "        embed_time,\n",
    "        recon_time,\n",
    "        embed_time + recon_time,\n",
    "        len(X_test_flat)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.287512Z",
     "start_time": "2020-07-17T23:37:13.863Z"
    }
   },
   "outputs": [],
   "source": [
    "X_recon = pca.inverse_transform(pca.transform(X_test_flat))\n",
    "x_real = X_test.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n",
    "x_recon = X_recon.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n",
    "\n",
    "MSE = mean_squared_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MAE = mean_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MedAE = median_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "R2 = r2_score(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "\n",
    "reconstruction_acc_df.loc[len(reconstruction_acc_df)] = ['pca', 2, dataset, MSE, MAE, MedAE, R2]\n",
    "reconstruction_acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 64 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.288700Z",
     "start_time": "2020-07-17T23:37:13.865Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=64)\n",
    "z = pca.fit_transform(X_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.289694Z",
     "start_time": "2020-07-17T23:37:13.867Z"
    }
   },
   "outputs": [],
   "source": [
    "n_repeats = 10\n",
    "for i in tqdm(range(n_repeats)):\n",
    "    start_time = time.monotonic()\n",
    "    z_test = pca.transform(X_test_flat);\n",
    "    end_time = time.monotonic()\n",
    "    print('seconds: ', end_time - start_time)\n",
    "    embed_time = end_time - start_time\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    x_test_recon = pca.inverse_transform(z_test);\n",
    "    end_time = time.monotonic()\n",
    "    print('seconds: ', end_time - start_time)\n",
    "    recon_time = (end_time - start_time)\n",
    "\n",
    "    reconstruction_speed_df.loc[len(reconstruction_speed_df)] = [\n",
    "        \"pca\",\n",
    "        64,\n",
    "        dataset,\n",
    "        embed_time,\n",
    "        recon_time,\n",
    "        embed_time + recon_time,\n",
    "        len(X_test_flat)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.290864Z",
     "start_time": "2020-07-17T23:37:13.869Z"
    }
   },
   "outputs": [],
   "source": [
    "X_recon = pca.inverse_transform(pca.transform(X_test_flat))\n",
    "x_real = X_test.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n",
    "x_recon = X_recon.reshape((len(X_test), np.product(np.shape(X_test)[1:])))\n",
    "\n",
    "MSE = mean_squared_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MAE = mean_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "MedAE = median_absolute_error(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "R2 = r2_score(\n",
    "    x_real, \n",
    "    x_recon\n",
    ")\n",
    "\n",
    "reconstruction_acc_df.loc[len(reconstruction_acc_df)] = ['pca', 64, dataset, MSE, MAE, MedAE, R2]\n",
    "reconstruction_acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.291910Z",
     "start_time": "2020-07-17T23:37:13.871Z"
    }
   },
   "outputs": [],
   "source": [
    "save_loc = DATA_DIR / 'reconstruction_speed' / (dataset + '.pickle')\n",
    "ensure_dir(save_loc)\n",
    "reconstruction_speed_df.to_pickle(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T23:37:31.293005Z",
     "start_time": "2020-07-17T23:37:13.872Z"
    }
   },
   "outputs": [],
   "source": [
    "save_loc = DATA_DIR / 'reconstruction_acc' / (dataset + '.pickle')\n",
    "ensure_dir(save_loc)\n",
    "reconstruction_acc_df.to_pickle(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
