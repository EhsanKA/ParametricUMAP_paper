{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- add reconstruction\n",
    "- add validation\n",
    "- add saving (?) or fix saving to be pickle-able (add warning to __get_state__ that keras embeddings are not pickleable)\n",
    "- add non-parametric embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:25:51.342961Z",
     "start_time": "2020-08-13T22:25:51.236296Z"
    }
   },
   "outputs": [],
   "source": [
    "# reload packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:25:51.530414Z",
     "start_time": "2020-08-13T22:25:51.515213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:25:55.612769Z",
     "start_time": "2020-08-13T22:25:51.639362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpu_devices)>0:\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "print(gpu_devices)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:25:56.567957Z",
     "start_time": "2020-08-13T22:25:55.614289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tfumap.load_datasets import load_MNIST, mask_labels\n",
    "X_train, X_test, X_valid, Y_train, Y_test, Y_valid = load_MNIST(flatten=False)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:00.736801Z",
     "start_time": "2020-08-13T22:25:56.569763Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from umap import UMAP\n",
    "from warnings import warn\n",
    "from umap.umap_ import make_epochs_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:00.779118Z",
     "start_time": "2020-08-13T22:26:00.738637Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_graph_elements(graph_, n_epochs):\n",
    "    \"\"\"\n",
    "    gets elements of graphs, weights, and number of epochs per edge\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph_ : [type]\n",
    "        umap graph of probabilities\n",
    "    n_epochs : int\n",
    "        maximum number of epochs per edge\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    graph [type]\n",
    "        umap graph\n",
    "    epochs_per_sample np.array\n",
    "        number of epochs to train each sample for\n",
    "    head np.array\n",
    "        edge head\n",
    "    tail np.array\n",
    "        edge tail\n",
    "    weight np.array\n",
    "        edge weight\n",
    "    n_vertices int\n",
    "        number of verticies in graph\n",
    "    \"\"\"\n",
    "    ### should we remove redundancies () here??\n",
    "    # graph_ = remove_redundant_edges(graph_)\n",
    "\n",
    "    graph = graph_.tocoo()\n",
    "    # eliminate duplicate entries by summing them together\n",
    "    graph.sum_duplicates()\n",
    "    # number of vertices in dataset\n",
    "    n_vertices = graph.shape[1]\n",
    "    # get the number of epochs based on the size of the dataset\n",
    "    if n_epochs is None:\n",
    "        # For smaller datasets we can use more epochs\n",
    "        if graph.shape[0] <= 10000:\n",
    "            n_epochs = 500\n",
    "        else:\n",
    "            n_epochs = 200\n",
    "    # remove elements with very low probability\n",
    "    graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0\n",
    "    graph.eliminate_zeros()\n",
    "    # get epochs per sample based upon edge probability\n",
    "    epochs_per_sample = make_epochs_per_sample(graph.data, n_epochs)\n",
    "\n",
    "    head = graph.row\n",
    "    tail = graph.col\n",
    "    weight = graph.data\n",
    "\n",
    "    return graph, epochs_per_sample, head, tail, weight, n_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:00.811490Z",
     "start_time": "2020-08-13T22:26:00.780460Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_distance_to_probability(distances, a, b):\n",
    "    \"\"\" convert distance representation into probability, \n",
    "        as a function of a, b params\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + a * distances ** (2 * b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:00.843929Z",
     "start_time": "2020-08-13T22:26:00.812769Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cross_entropy(\n",
    "    probabilities_graph, probabilities_distance, EPS=1e-4, repulsion_strength=1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute cross entropy between low and high probability\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    probabilities_graph : [type]\n",
    "        high dimensional probabilities\n",
    "    probabilities_distance : [type]\n",
    "        low dimensional probabilities\n",
    "    EPS : [type], optional\n",
    "        offset to to ensure log is taken of a positive number, by default 1e-4\n",
    "    repulsion_strength : float, optional\n",
    "        strength of repulsion between negative samples, by default 1.0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    attraction_term: tf.float32\n",
    "        attraction term for cross entropy loss\n",
    "    repellant_term: tf.float32\n",
    "        repellant term for cross entropy loss\n",
    "    cross_entropy: tf.float32\n",
    "        cross entropy umap loss\n",
    "    \n",
    "    \"\"\"\n",
    "    # cross entropy\n",
    "    attraction_term = -probabilities_graph * tf.math.log(\n",
    "        tf.clip_by_value(probabilities_distance, EPS, 1.0)\n",
    "    )\n",
    "    repellant_term = (\n",
    "        -(1.0 - probabilities_graph)\n",
    "        * tf.math.log(tf.clip_by_value(1.0 - probabilities_distance, EPS, 1.0))\n",
    "        * repulsion_strength\n",
    "    )\n",
    "\n",
    "    # balance the expected losses between atrraction and repel\n",
    "    CE = attraction_term + repellant_term\n",
    "    return attraction_term, repellant_term, CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:00.878521Z",
     "start_time": "2020-08-13T22:26:00.845254Z"
    }
   },
   "outputs": [],
   "source": [
    "def umap_loss(batch_size, negative_sample_rate, _a, _b, repulsion_strength=1.0):\n",
    "    @tf.function\n",
    "    def loss(placeholder_y, embed_to_from):\n",
    "        # split out to/from\n",
    "        embedding_to, embedding_from = tf.split(\n",
    "            embed_to_from, num_or_size_splits=2, axis=1\n",
    "        )\n",
    "\n",
    "        # get negative samples\n",
    "        embedding_neg_to = tf.repeat(embedding_to, negative_sample_rate, axis=0)\n",
    "        repeat_neg = tf.repeat(embedding_from, negative_sample_rate, axis=0)\n",
    "        embedding_neg_from = tf.gather(\n",
    "            repeat_neg, tf.random.shuffle(tf.range(tf.shape(repeat_neg)[0]))\n",
    "        )\n",
    "\n",
    "        #  distances between samples (and negative samples)\n",
    "        distance_embedding = tf.concat(\n",
    "            [\n",
    "                tf.norm(embedding_to - embedding_from, axis=1),\n",
    "                tf.norm(embedding_neg_to - embedding_neg_from, axis=1),\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # convert probabilities to distances\n",
    "        probabilities_distance = convert_distance_to_probability(\n",
    "            distance_embedding, _a, _b\n",
    "        )\n",
    "\n",
    "        # set true probabilities based on negative sampling\n",
    "        probabilities_graph = tf.concat(\n",
    "            [tf.ones(batch_size), tf.zeros(batch_size * negative_sample_rate)], axis=0,\n",
    "        )\n",
    "\n",
    "        # compute cross entropy\n",
    "        (attraction_loss, repellant_loss, ce_loss) = compute_cross_entropy(\n",
    "            probabilities_graph,\n",
    "            probabilities_distance,\n",
    "            repulsion_strength=repulsion_strength,\n",
    "        )\n",
    "        return tf.reduce_mean(ce_loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:00.913456Z",
     "start_time": "2020-08-13T22:26:00.880419Z"
    }
   },
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def umap_loss__(embed_to_from, batch_size, negative_sample_rate, _a, _b, repulsion_strength=1.0):\n",
    "    \n",
    "    # split out to/from\n",
    "    embedding_to, embedding_from = tf.split(\n",
    "        embed_to_from, num_or_size_splits=2, axis=1\n",
    "    )\n",
    "\n",
    "    # get negative samples\n",
    "    embedding_neg_to = tf.repeat(embedding_to, negative_sample_rate, axis=0)\n",
    "    repeat_neg = tf.repeat(embedding_from, negative_sample_rate, axis=0)\n",
    "    embedding_neg_from = tf.gather(\n",
    "        repeat_neg, tf.random.shuffle(tf.range(tf.shape(repeat_neg)[0]))\n",
    "    )\n",
    "\n",
    "    #  distances between samples (and negative samples)\n",
    "    distance_embedding = tf.concat(\n",
    "        [\n",
    "            tf.norm(embedding_to - embedding_from, axis=1),\n",
    "            tf.norm(embedding_neg_to - embedding_neg_from, axis=1),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    # convert probabilities to distances\n",
    "    probabilities_distance = convert_distance_to_probability(\n",
    "        distance_embedding, _a, _b\n",
    "    )\n",
    "\n",
    "    # set true probabilities based on negative sampling\n",
    "    probabilities_graph = tf.concat(\n",
    "        [tf.ones(batch_size), tf.zeros(batch_size * negative_sample_rate)], axis=0,\n",
    "    )\n",
    "\n",
    "    # compute cross entropy\n",
    "    (attraction_loss, repellant_loss, ce_loss) = compute_cross_entropy(\n",
    "        probabilities_graph,\n",
    "        probabilities_distance,\n",
    "        repulsion_strength=repulsion_strength,\n",
    "    )\n",
    "    return tf.cast(tf.reduce_mean(ce_loss), tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:00.949883Z",
     "start_time": "2020-08-13T22:26:00.914886Z"
    }
   },
   "outputs": [],
   "source": [
    "from umap.spectral import spectral_layout\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "\n",
    "def init_embedding_from_graph(\n",
    "    _raw_data, graph, n_components, random_state, metric, _metric_kwds, init=\"spectral\"\n",
    "):\n",
    "    \"\"\" Initialize embedding using graph. This is for direct embeddings. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        init : str, optional\n",
    "            Type of initialization to use. Either random, or spectral, by default \"spectral\"\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        embedding : np.array\n",
    "            the initialized embedding\n",
    "        \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = check_random_state(None)\n",
    "    \n",
    "    if isinstance(init, str) and init == \"random\":\n",
    "        embedding = random_state.uniform(\n",
    "            low=-10.0, high=10.0, size=(graph.shape[0], n_components)\n",
    "        ).astype(np.float32)\n",
    "    elif isinstance(init, str) and init == \"spectral\":\n",
    "        # We add a little noise to avoid local minima for optimization to come\n",
    "\n",
    "        initialisation = spectral_layout(\n",
    "            _raw_data,\n",
    "            graph,\n",
    "            n_components,\n",
    "            random_state,\n",
    "            metric=metric,\n",
    "            metric_kwds=_metric_kwds,\n",
    "        )\n",
    "        expansion = 10.0 / np.abs(initialisation).max()\n",
    "        embedding = (initialisation * expansion).astype(\n",
    "            np.float32\n",
    "        ) + random_state.normal(\n",
    "            scale=0.0001, size=[graph.shape[0], n_components]\n",
    "        ).astype(\n",
    "            np.float32\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        init_data = np.array(init)\n",
    "        if len(init_data.shape) == 2:\n",
    "            if np.unique(init_data, axis=0).shape[0] < init_data.shape[0]:\n",
    "                tree = KDTree(init_data)\n",
    "                dist, ind = tree.query(init_data, k=2)\n",
    "                nndist = np.mean(dist[:, 1])\n",
    "                embedding = init_data + random_state.normal(\n",
    "                    scale=0.001 * nndist, size=init_data.shape\n",
    "                ).astype(np.float32)\n",
    "            else:\n",
    "                embedding = init_data\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:00.983225Z",
     "start_time": "2020-08-13T22:26:00.951157Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_networks(\n",
    "    encoder, decoder, n_components, dims, n_data, parametric_embedding, init_embedding\n",
    "):\n",
    "\n",
    "    if parametric_embedding:\n",
    "        if encoder is None:\n",
    "            encoder = tf.keras.Sequential(\n",
    "                [\n",
    "                    tf.keras.layers.InputLayer(input_shape=dims),\n",
    "                    tf.keras.layers.Flatten(),\n",
    "                    tf.keras.layers.Dense(units=100, activation=\"relu\"),\n",
    "                    tf.keras.layers.Dense(units=100, activation=\"relu\"),\n",
    "                    tf.keras.layers.Dense(units=100, activation=\"relu\"),\n",
    "                    tf.keras.layers.Dense(units=n_components, name=\"z\"),\n",
    "                ]\n",
    "            )\n",
    "    else:\n",
    "        embedding_layer = tf.keras.layers.Embedding(\n",
    "            n_data, n_components, input_length=1\n",
    "        )\n",
    "        embedding_layer.build(input_shape=(1,)) \n",
    "        embedding_layer.set_weights([init_embedding])\n",
    "        encoder = tf.keras.Sequential([embedding_layer])\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:01.022360Z",
     "start_time": "2020-08-13T22:26:00.984477Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_edge_dataset(\n",
    "    X,\n",
    "    graph_,\n",
    "    n_epochs,\n",
    "    batch_size,\n",
    "    max_sample_repeats_per_epoch,\n",
    "    parametric_embedding,\n",
    "    parametric_decoding,\n",
    "):\n",
    "    \"\"\" Construct a tf.data.Dataset of edges, sampled by edge weight.\n",
    "    \"\"\"\n",
    "\n",
    "    def gather_X(edge_to, edge_from):\n",
    "        return (tf.gather(X, edge_to), tf.gather(X, edge_from)), 0\n",
    "    def nonparametric_gather_X(edge_to, edge_from):\n",
    "        return (tf.expand_dims(edge_to, -1), tf.expand_dims(edge_from, -1)), tf.cast([0.0], tf.float32)\n",
    "\n",
    "    # get data from graph\n",
    "    graph, epochs_per_sample, head, tail, weight, n_vertices = get_graph_elements(\n",
    "        graph_, n_epochs\n",
    "    )\n",
    "\n",
    "    # number of elements per batch for embedding\n",
    "    if batch_size is None:\n",
    "        # batch size can be larger if its just over embeddings\n",
    "        if (parametric_embedding == False) & (parametric_decoding is None):\n",
    "            batch_size = np.min([n_vertices, 60000])\n",
    "        else:\n",
    "            batch_size = np.min([n_vertices, 1000])\n",
    "\n",
    "    edges_to_exp, edges_from_exp = (\n",
    "        np.repeat(head, epochs_per_sample.astype(\"int\")),\n",
    "        np.repeat(tail, epochs_per_sample.astype(\"int\")),\n",
    "    )\n",
    "\n",
    "    # shuffle edges\n",
    "    shuffle_mask = np.random.permutation(range(len(edges_to_exp)))\n",
    "    edges_to_exp = edges_to_exp[shuffle_mask]\n",
    "    edges_from_exp = edges_from_exp[shuffle_mask]\n",
    "\n",
    "    # create edge iterator\n",
    "    edge_dataset = tf.data.Dataset.from_tensor_slices((edges_to_exp, edges_from_exp))\n",
    "    edge_dataset = edge_dataset.repeat()\n",
    "    edge_dataset = edge_dataset.shuffle(10000)\n",
    "    if parametric_embedding:\n",
    "        edge_dataset = edge_dataset.map(\n",
    "            gather_X, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "        )\n",
    "    else:\n",
    "        edge_dataset = edge_dataset.map(\n",
    "            nonparametric_gather_X, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "        )\n",
    "    edge_dataset = edge_dataset.batch(batch_size, drop_remainder=True)\n",
    "    edge_dataset = edge_dataset.prefetch(10)\n",
    "    return edge_dataset, batch_size, len(edges_to_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:48.530209Z",
     "start_time": "2020-08-13T22:26:48.465688Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParametricUMAP(UMAP):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer=None,\n",
    "        batch_size=None,\n",
    "        dims=None,\n",
    "        encoder=None,\n",
    "        decoder=None,\n",
    "        parametric_embedding=True,\n",
    "        parametric_decoding=False,\n",
    "        autoencoder_decoding=False,\n",
    "        max_sample_repeats_per_epoch=None,\n",
    "        loss_report_frequency=1,\n",
    "        n_training_epochs=1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\" Parametric UMAP subclassing UMAP-learn, based on keras/tensorflow.\n",
    "        There is also a non-parametric implementation contained within to compare \n",
    "        with the base non-parametric implementation.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # add to network\n",
    "        self.dims = dims  # if this is an image, we should reshape for network\n",
    "        self.encoder = encoder  # neural network used for embedding\n",
    "        self.decoder = decoder  # neural network used for decoding\n",
    "        self.parametric_embedding = (\n",
    "            parametric_embedding  # nonparametric vs parametric embedding\n",
    "        )\n",
    "        self.parametric_decoding = parametric_decoding\n",
    "        self.max_sample_repeats_per_epoch = max_sample_repeats_per_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_report_frequency = (\n",
    "            loss_report_frequency  # how many times per epoch to report loss in keras\n",
    "        )\n",
    "        # how many epochs to train for (different than n_epochs which is specific to each sample)\n",
    "        self.n_training_epochs = n_training_epochs\n",
    "        # set optimizer\n",
    "        if optimizer is None:\n",
    "            if parametric_embedding:\n",
    "                # Adam is better for parametric_embedding\n",
    "                self.optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "            else:\n",
    "                # Adadelta is better for direct embedding\n",
    "                self.optimizer = tf.keras.optimizers.Adadelta(50)\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "\n",
    "    def define_model(self):\n",
    "        \"\"\" Define the model in keras\n",
    "        \"\"\"\n",
    "\n",
    "        # inputs\n",
    "        if self.parametric_embedding:\n",
    "            to_x = tf.keras.layers.Input(shape=self.dims, name=\"to_x\")\n",
    "            from_x = tf.keras.layers.Input(shape=self.dims, name=\"from_x\")\n",
    "            embedding_to = self.encoder(to_x)\n",
    "            embedding_from = self.encoder(from_x)\n",
    "        else:\n",
    "            to_x = tf.keras.layers.Input(shape=(1), name=\"to_x\")\n",
    "            from_x = tf.keras.layers.Input(shape=(1), name=\"from_x\")\n",
    "            embedding_to = self.encoder(to_x)[:, -1, :]\n",
    "            embedding_from = self.encoder(from_x)[:, -1, :]\n",
    "        \n",
    "            print(embedding_to)\n",
    "        # batch_size, negative_sample_rate, _a, _b, repulsion_strength\n",
    "        # get negative samples\n",
    "        embedding_neg_to = tf.repeat(embedding_to, self.negative_sample_rate, axis=0)\n",
    "        repeat_neg = tf.repeat(embedding_from, self.negative_sample_rate, axis=0)\n",
    "        embedding_neg_from = tf.gather(\n",
    "            repeat_neg, tf.random.shuffle(tf.range(tf.shape(repeat_neg)[0]))\n",
    "        )\n",
    "\n",
    "        #  distances between samples (and negative samples)\n",
    "        distance_embedding = tf.concat(\n",
    "            [\n",
    "                tf.norm(embedding_to - embedding_from, axis=1),\n",
    "                tf.norm(embedding_neg_to - embedding_neg_from, axis=1),\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # convert probabilities to distances\n",
    "        probabilities_distance = convert_distance_to_probability(\n",
    "            distance_embedding, tf.cast(self._a, tf.float32), tf.cast(self._b, tf.float32)\n",
    "        )\n",
    "\n",
    "        # set true probabilities based on negative sampling\n",
    "        probabilities_graph = tf.concat(\n",
    "            [tf.ones(self.batch_size), tf.zeros(self.batch_size * self.negative_sample_rate)], axis=0,\n",
    "        )\n",
    "\n",
    "        # compute cross entropy\n",
    "        (attraction_loss, repellant_loss, ce_loss) = compute_cross_entropy(\n",
    "            probabilities_graph,\n",
    "            probabilities_distance,\n",
    "            repulsion_strength=self.repulsion_strength,\n",
    "        )\n",
    "        \n",
    "        umap_loss = tf.reduce_mean(ce_loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # create model\n",
    "        self.parametric_model = tf.keras.Model(\n",
    "            inputs=[to_x, from_x], outputs={\"umap\": umap_loss},\n",
    "        )\n",
    "\n",
    "    def compile_model(self):\n",
    "\n",
    "        self.parametric_model.compile(\n",
    "            optimizer=self.optimizer,\n",
    "            loss={\n",
    "                # \"reconstruction\": tf.keras.losses.BinaryCrossentropy(),\n",
    "                \"umap\": \"mae\",\n",
    "            },\n",
    "            loss_weights={\"umap\": 1.0},\n",
    "        )\n",
    "\n",
    "    def _fit_embed_data(self, X, n_epochs, init, random_state):\n",
    "\n",
    "        # get dimensionality of dataset\n",
    "        if self.dims is None:\n",
    "            self.dims = [np.shape(X)[-1]]\n",
    "        else:\n",
    "            # reshape data for network\n",
    "            if len(self.dims) > 1:\n",
    "                X = np.reshape(X, [len(X)] + list(self.dims))\n",
    "\n",
    "        self.n_data = len(X)\n",
    "\n",
    "        # get dataset of edges\n",
    "        edge_dataset, self.batch_size, n_edges = construct_edge_dataset(\n",
    "            X,\n",
    "            self.graph_,\n",
    "            self.n_epochs,\n",
    "            self.batch_size,\n",
    "            self.max_sample_repeats_per_epoch,\n",
    "            self.parametric_embedding,\n",
    "            self.parametric_decoding,\n",
    "        )\n",
    "\n",
    "        if not self.parametric_embedding:\n",
    "            init_embedding = init_embedding_from_graph(\n",
    "                X,\n",
    "                self.graph_,\n",
    "                self.n_components,\n",
    "                self.random_state,\n",
    "                self.metric,\n",
    "                self._metric_kwds,\n",
    "                init=\"spectral\",\n",
    "            )\n",
    "\n",
    "        # create encoder and decoder model\n",
    "        self.encoder, self.decoder = prepare_networks(\n",
    "            self.encoder,\n",
    "            self.decoder,\n",
    "            self.n_components,\n",
    "            self.dims,\n",
    "            self.n_data,\n",
    "            self.parametric_embedding,\n",
    "            init_embedding,\n",
    "        )\n",
    "\n",
    "        # create the model\n",
    "        self.define_model()\n",
    "        self.compile_model()\n",
    "\n",
    "        # report every loss_report_frequency subdivision of an epochs\n",
    "        steps_per_epoch = int(n_edges / self.batch_size / self.loss_report_frequency)\n",
    "\n",
    "        # create embedding\n",
    "        self._history = self.parametric_model.fit(\n",
    "            edge_dataset,\n",
    "            epochs=self.loss_report_frequency * self.n_training_epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            max_queue_size=100,\n",
    "        )\n",
    "\n",
    "        embedding = self.encoder.predict(X, verbose=True)\n",
    "\n",
    "        return embedding, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:48.787006Z",
     "start_time": "2020-08-13T22:26:48.748684Z"
    }
   },
   "outputs": [],
   "source": [
    "dims = (28,28, 1)\n",
    "n_components = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:48.928500Z",
     "start_time": "2020-08-13T22:26:48.891792Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ParametricUMAP(\n",
    "    \n",
    "    parametric_embedding=False, dims=dims, loss_report_frequency=5, n_training_epochs=5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:49.079870Z",
     "start_time": "2020-08-13T22:26:49.043858Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape((len(X_train), np.product(np.shape(X_train)[1:])))\n",
    "X_train_flat = X_train_flat[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:26:54.907916Z",
     "start_time": "2020-08-13T22:26:49.336953Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParametricUMAP(autoencoder_decoding=None, dims=(28, 28, 1),\n",
      "               loss_report_frequency=5, n_training_epochs=5,\n",
      "               optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7fdb285b1c50>,\n",
      "               parametric_embedding=False)\n",
      "Construct fuzzy simplicial set\n",
      "Thu Aug 13 15:26:49 2020 Finding Nearest Neighbors\n",
      "Thu Aug 13 15:26:49 2020 Finished Nearest Neighbor Search\n",
      "Thu Aug 13 15:26:49 2020 Construct embedding\n",
      "Tensor(\"strided_slice_1:0\", shape=(None, 2), dtype=float32)\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3171\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2989\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2853\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.2780\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2704\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2676\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2639\n",
      "Epoch 8/25\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2599"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ba2465c7f7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/cube/tsainbur/Projects/github_repos/umap/umap/umap_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         self.embedding_, aux_data = self._fit_embed_data(\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# JH why raw data?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m         )\n\u001b[1;32m   2324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-b20827e72e7a>\u001b[0m in \u001b[0;36m_fit_embed_data\u001b[0;34m(self, X, n_epochs, init, random_state)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_report_frequency\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_training_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         )\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding = model.fit(X_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:02:15.271669Z",
     "start_time": "2020-08-13T22:02:14.711620Z"
    }
   },
   "outputs": [],
   "source": [
    "z = model.encoder.trainable_variables[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:02:15.313234Z",
     "start_time": "2020-08-13T22:02:15.273848Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T22:02:15.544137Z",
     "start_time": "2020-08-13T22:02:15.314674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots( figsize=(8, 8))\n",
    "sc = ax.scatter(\n",
    "    z[:, 0],\n",
    "    z[:, 1],\n",
    "    c=Y_train.astype(int)[:len(z)],\n",
    "    cmap=\"tab10\",\n",
    "    s=0.1,\n",
    "    alpha=0.5,\n",
    "    rasterized=True,\n",
    ")\n",
    "ax.axis('equal')\n",
    "ax.set_title(\"UMAP in Tensorflow embedding\", fontsize=20)\n",
    "plt.colorbar(sc, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T21:34:47.966429Z",
     "start_time": "2020-08-13T21:34:21.451Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(model._history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
